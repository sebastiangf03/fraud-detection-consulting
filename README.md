# fraud-detection-consulting
Optimizaci√≥n de modelos de Machine Learning para detecci√≥n de fraude financiero. Comparativa estrat√©gica entre Under-sampling y SMOTE aplicada a Regresi√≥n Log√≠stica y Random Forest para la gesti√≥n de riesgo bancario

# üõ°Ô∏è Detecci√≥n de Fraude Bancario: Un Enfoque de Consultor√≠a Estrat√©gica

## üìå Resumen Ejecutivo
Este proyecto aborda un desaf√≠o cr√≠tico en el sector financiero: la detecci√≥n de transacciones fraudulentas en tiempo real en un dataset altamente desbalanceado.

Analizando m√°s de 280,000 transacciones donde el fraude representa apenas el **0.17%**, el objetivo principal no fue solo maximizar la detecci√≥n t√©cnica, sino encontrar el equilibrio estrat√©gico entre dos KPIs de negocio opuestos:
1.  **Minimizar P√©rdidas Financieras:** Capturar la mayor cantidad de fraude posible (Alto Recall).
2.  **Proteger la Experiencia del Cliente:** Evitar bloquear tarjetas leg√≠timas por error (Alta Precisi√≥n).

---

## üõ†Ô∏è Metodolog√≠a y Desaf√≠o T√©cnico

El principal reto fue la escasez de datos de fraude. Se implementaron y compararon diferentes estrategias de ingenier√≠a de datos para superar esto:

* **Preprocesamiento Robusto:** Uso de `RobustScaler` para neutralizar el impacto de valores at√≠picos extremos en los montos de transacci√≥n.
* **Estrategia de Muestreo A (Under-sampling):** Reducci√≥n de la clase mayoritaria para un prototipado r√°pido y eficiente.
* **Estrategia de Muestreo B (SMOTE):** Generaci√≥n de datos sint√©ticos para entrenar con el volumen completo.
    * *Datos Reales:* 396 fraudes.
    * *Datos tras SMOTE:* 226,584 fraudes sint√©ticos (Equilibrado).

### üìä Visualizaci√≥n del Impacto del Balanceo
El desbalance oculta los patrones. Al equilibrar los datos, las verdaderas correlaciones del fraude emergen claramente:

![Comparativa de Correlaci√≥n](images/Matriz-de-Correlacion.png)
*Figura 1: La matriz inferior (equilibrada) revela fuertes correlaciones negativas (rojo intenso) en variables como V14 y V12 que estaban ocultas en el dataset original.*

---

## üìà Benchmark de Rendimiento (Resultados Reales)

Se evaluaron tres escenarios para determinar el modelo √≥ptimo para producci√≥n:

| Estrategia | Algoritmo | Precision (Fiabilidad) | Recall (Detecci√≥n) | An√°lisis del Consultor |
| :--- | :--- | :--- | :--- | :--- |
| **L√≠nea Base** | Log√≠stica + Under-sampling | **94%** | **87%** | Excelente equilibrio y rapidez para un primer despliegue. |
| **Experimento** | Log√≠stica + SMOTE | 4% | 88% | **Inviable.** El ruido sint√©tico destruy√≥ la fiabilidad del modelo. |
| **Soluci√≥n Final**| **Random Forest + SMOTE** | **91%** | **81%** | Modelo robusto que recupera la precisi√≥n y maneja la complejidad. |

---

## üß† An√°lisis Profundo: La Trampa de la Complejidad

### El Fracaso de SMOTE con Modelos Lineales
El intento de usar SMOTE con una Regresi√≥n Log√≠stica simple result√≥ en un fracaso operativo. El modelo no pudo distinguir entre transacciones reales y el "ruido" generado sint√©ticamente, resultando en una precisi√≥n del 4%.
> **Impacto de Negocio:** De cada 100 bloqueos de tarjeta, 96 ser√≠an a clientes inocentes. Inaceptable para un banco.

![Matriz Log√≠stica SMOTE](images/Matriz-Confusion-SMOTE.png,images/SMOTE.png)
*Figura 2: La Regresi√≥n Log√≠stica con SMOTE gener√≥ 1470 Falsos Positivos (esquina superior derecha), desplomando la precisi√≥n.*

### La Soluci√≥n Robusta: Random Forest
Al aplicar un algoritmo de ensamble (Random Forest), logramos "domar" los datos sint√©ticos de SMOTE. El modelo fue capaz de aprender fronteras de decisi√≥n complejas, elevando la precisi√≥n de nuevo a un nivel de producci√≥n (91%).

![Matriz Random Forest](images/Matriz-Confusion-RF+SMOTE.png,images/RF.png)
*Figura 3: El Random Forest redujo dr√°sticamente los falsos positivos a solo 6, ofreciendo un sistema altamente fiable.*

---

## üí° Recomendaci√≥n Final del Consultor

Para una instituci√≥n financiera que prioriza la **reducci√≥n de la fricci√≥n con el cliente** y la **estabilidad a largo plazo**, se recomienda la implementaci√≥n del modelo **Random Forest con entrenamiento SMOTE**.

Aunque su tasa de detecci√≥n (Recall 81%) es ligeramente inferior a la l√≠nea base, su **Precisi√≥n del 91%** garantiza que el equipo de revisi√≥n de fraudes no pierda tiempo en falsas alarmas y que los clientes leg√≠timos no sufran bloqueos injustificados.

---
**Autor:** Sebastian David Gutierrez Ferreira
*Data Science & Analytics Portfolio*
[Enlace a tu LinkedIn]
